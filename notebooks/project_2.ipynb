{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355fbe97",
   "metadata": {},
   "source": [
    "# Project 2 - Reinforcement Learning - MO436"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c1a50",
   "metadata": {},
   "source": [
    "**Group:** \n",
    "* Arthur Guazzelli (234984)\n",
    "* Elian Laura (265685)\n",
    "* Iury Cleveston (230216)\n",
    "* Maria Tejada (197488)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13e1465",
   "metadata": {},
   "source": [
    "## 1) Environment Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35852b",
   "metadata": {},
   "source": [
    "In this project, we used the FrozenLake $8\\times8$ environment from OpenAi Gym. This environment is represented as a grid with $8\\times8$ tiles, where the goal is to cross the entire board without falling into ice holes. Frozen Lake is an episodic environment, where the initial state (S) is in the top-left position, and the terminal states are either the ice holes (H) or the final goal in the bottom-right tile (G). The ice holes are spread across the board, and the agent should find a path to the goal through frozen tiles (F); the reward of value of $1$ is only given at this point.\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "<center><img src=\"frozenLake.png\" width=\"180\"/></center>\n",
    "<center>Figure 1 - Frozen Lake Grid.</center>\n",
    "</div>\n",
    "\n",
    "\n",
    "The current state is represented as a single number corresponding to the tile where the agent has entered, ranging from $0$ to $63$; therefore, this environment is discrete and partial observable. The possible actions are moving north, east, south, and west. Frozen Lake is presented in a deterministic and stochastic way; the difference is in the slippery ice, where the agent might slip and move to one of the four directions.\n",
    "\n",
    "The ice holes are close to feasible paths to the goal; also, the reward is delayed until the end. These characteristics make Frozen Lake a challenging environment, especially in the stochastic version, where the dynamics are unpredictable.\n",
    "\n",
    "Codes are available at https://github.com/thurbridi/mo436-project-1\n",
    "\n",
    "Video are available at https://www.youtube.com/watch?v=S3_mXpYOIWU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6461026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746365c",
   "metadata": {},
   "source": [
    "## 2) Off-policy methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8dbb75",
   "metadata": {},
   "source": [
    "### 2.1) DQN (Elian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f5c0c",
   "metadata": {},
   "source": [
    "### 2.2) SAC (Maria)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456f2f84",
   "metadata": {},
   "source": [
    "## 3) On-policy methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b882de8",
   "metadata": {},
   "source": [
    "### 3.1) REINFORCE (Iury)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824fc2ef",
   "metadata": {},
   "source": [
    "### 3.2) PPO (Arthur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3defb3",
   "metadata": {},
   "source": [
    "## 3) Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c226b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
