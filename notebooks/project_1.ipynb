{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - Reinforcement Learning - MO436"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group: Arthur Guazzelli, Elian, Iury Cleveston, Maria Tejada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Environment Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we used the FrozenLake 8x8 environment from OpenAi Gym. This environment is represented as a grid with 8x8 tiles, where the goal is to cross the entire board without falling into ice holes. Frozen Lake is an episodic environment, where the initial state (S) is in the top-left position, and the terminal states are either the ice holes (H) or the final goal in the bottom-right tile (G). The ice holes are spread across the board, and the agent should find a path to the goal through frozen tiles (F); the reward of value of 1 is only given at this point.\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "<center><img src=\"board.png\" width=\"100\"/></center>\n",
    "<center>Figure 1 - Frozen Lake Grid.</center>\n",
    "</div>\n",
    "\n",
    "\n",
    "The current state is represented as a single number corresponding to the tile where the agent has entered, ranging from 0 to 63; therefore, this environment is discrete and partial observable. The possible actions are moving north, east, south, and west. Frozen Lake is presented in a deterministic and stochastic way; the difference is in the slippery ice, where the agent might slip and reach an unexpected state.\n",
    "\n",
    "The ice holes are close to feasible paths to the goal; also, the reward is delayed until the end. These characteristics make Frozen Lake a challenging environment, especially in the stochastic version, where the dynamics are unpredictable.\n",
    "\n",
    "Codes are available at https://github.com/thurbridi/mo436-project-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2) Monte Carlo Control (iury)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The Monte Carlo Agent was initialized with the state-action values $Q(s, a)$ equal to 0. We employed a step-size $\\alpha_{t} = \\frac{1}{N(s_{t},a_{t})}$, where $N(s_{t},a_{t})$ refers to the number of times action $a$ was selected from the state $s$.\n",
    "\n",
    "The trade-off between exploration and exploitation was determined by an $\\epsilon-greedy$ policy, where $\\epsilon_{t} = \\frac{N0}{N0+N(s_{t})}$; $N0$ is an hyperparameter, and $N(s_{t})$ is the number of times the state $s$ has been visited. \n",
    "\n",
    "In this project, we implemented two versions: tabular and linear approximation. Also, we searched for the best parameters using grid search, and we evaluated the solutions in the deterministic and stochastic environment.\n",
    "\n",
    "The equation used for tabular Monte Carlo improvement is:\n",
    "\n",
    "$Q(s,a) = Q(s,a) + \\frac{1}{N(s,a)}(G_{t} - Q(s,a))$,\n",
    "\n",
    "where $G_{t} = \\sum \\gamma^{T-1}R_{k,T}$, and $N(s,a) = N(s,a) + 1$\n",
    "\n",
    "For policy evaluation, we used:\n",
    "\n",
    "$\\pi(s) = \\mathrm{argmax} Q(s,a)$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from monte_carlo_tabular import *\n",
    "from monte_carlo_approximator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.1) Tabular & Deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The first experiment consisted in applying the Monte Carlo First Visit in the tabular and deterministic environment. Therefore, we used a grid search technique to find the best solution given the parameters defined as:\n",
    "\n",
    "$\\mathrm{N0} \\in [0.1, 1, 10]$,\n",
    "\n",
    "$\\mathrm{gamma} \\in [1, 0.9, 0.5, 0.1]$,\n",
    "\n",
    "$\\mathrm{episodes} \\in [100, 1000]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      n0  gamma  episodes  win/loss (%)  elapsed time (s)\n",
      "0    0.1    1.0     100.0         100.0          0.226304\n",
      "1    1.0    1.0     100.0         100.0          0.189473\n",
      "2   10.0    1.0     100.0           2.0          0.072398\n",
      "3    0.1    0.9     100.0         100.0          0.126679\n",
      "4    1.0    0.9     100.0         100.0          0.124684\n",
      "5   10.0    0.9     100.0           2.0          0.089683\n",
      "6    0.1    0.5     100.0         100.0          0.145805\n",
      "7    1.0    0.5     100.0         100.0          0.095972\n",
      "8   10.0    0.5     100.0           2.0          0.069440\n",
      "9    0.1    0.1     100.0         100.0          0.108018\n",
      "10   1.0    0.1     100.0         100.0          0.075810\n",
      "11  10.0    0.1     100.0           2.0          0.064267\n",
      "12   0.1    1.0    1000.0         100.0          0.421142\n",
      "13   1.0    1.0    1000.0         100.0          0.392267\n",
      "14  10.0    1.0    1000.0         100.0          1.148584\n",
      "15   0.1    0.9    1000.0         100.0          0.294481\n",
      "16   1.0    0.9    1000.0         100.0          0.284455\n",
      "17  10.0    0.9    1000.0         100.0          0.335180\n",
      "18   0.1    0.5    1000.0         100.0          0.339937\n",
      "19   1.0    0.5    1000.0         100.0          0.270930\n",
      "20  10.0    0.5    1000.0         100.0          0.279343\n",
      "21   0.1    0.1    1000.0         100.0          0.297840\n",
      "22   1.0    0.1    1000.0         100.0          0.265978\n",
      "23  10.0    0.1    1000.0         100.0          0.261827\n"
     ]
    }
   ],
   "source": [
    "grid_search_tabular(stochastic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we varied the $N0$, gamma, and episodes. The win/loss metric is defined as the percentage of wins from 100 games plays; the majority of executions returned 100\\% of wins. Only the executions with $N0=10$ and with 100 episodes could not achieved maximum success, due to the excessive exploration. The elapsed time presented a consistent correlation with the number of episodes.\n",
    "\n",
    "We selected the execution number 4 to be analyzed in detail as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q, env = train_tabular(stochastic=False, episodes=100, gamma=0.9, n0=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative discounted reward (G) by episode increased during training; the average variance has also decreased, which means the agent is learning a good policy. The exploration rate is initially set as $N0=1$; however, as the training continues, the states are being visited, and the agent started to select greedy actions, contributing to the cumulative reward's variance decrease in the end. \n",
    "\n",
    "The final board is shown below, where the agent was able to reach its goal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFF\u001b[41mG\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We also reported the best state value ($V_*$) and the best policy ($\\pi_*$), as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t State Value\n",
      "------------------------------------------------\n",
      " 0.11| 0.14| 0.00| 0.22| 0.26| 0.30| 0.00| 0.00|\n",
      "------------------------------------------------\n",
      " 0.00| 0.14| 0.17| 0.20| 0.09| 0.37| 0.41| 0.04|\n",
      "------------------------------------------------\n",
      " 0.00| 0.03| 0.03| 0.00| 0.24| 0.05| 0.49| 0.56|\n",
      "------------------------------------------------\n",
      " 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.22| 0.60|\n",
      "------------------------------------------------\n",
      " 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.18| 0.74|\n",
      "------------------------------------------------\n",
      " 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.86|\n",
      "------------------------------------------------\n",
      " 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 1.00|\n",
      "------------------------------------------------\n",
      " 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00|\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_state_values_tabular(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t Policy/Actions\n",
      "------------------------------------------------\n",
      "  r  |  s  |  r  |  r  |  r  |  s  |  l  |  s  |\n",
      "------------------------------------------------\n",
      "  r  |  r  |  r  |  n  |  s  |  r  |  s  |  r  |\n",
      "------------------------------------------------\n",
      "  s  |  r  |  n  |  l  |  r  |  r  |  r  |  s  |\n",
      "------------------------------------------------\n",
      "  n  |  s  |  r  |  l  |  l  |  n  |  s  |  s  |\n",
      "------------------------------------------------\n",
      "  n  |  r  |  s  |  l  |  r  |  r  |  r  |  s  |\n",
      "------------------------------------------------\n",
      "  s  |  n  |  r  |  l  |  n  |  l  |  s  |  s  |\n",
      "------------------------------------------------\n",
      "  r  |  l  |  n  |  s  |  n  |  r  |  l  |  s  |\n",
      "------------------------------------------------\n",
      "  l  |  s  |  s  |  r  |  s  |  l  |  l  |  n  |\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_policy_tabular(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The policy is shown by state, where the greedy actions can be:\n",
    "<ul>\n",
    "    <li>n - north</li>\n",
    "    <li>r - right</li>\n",
    "    <li>s - south</li>\n",
    "    <li>l - left</li>\n",
    "</ul>\n",
    "\n",
    "Observing the $V_*$ plot and the best policy $\\pi_*$, we noted that the agent preferred to explore the top-right quadrant of the grid, mainly because the path seems less risky. In this sense, most of the actions are to go right and then south. The cumulative return (G) is appropriately assigned to the trajectory, being larger in the goal state, and decreasing its value until the initial state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.2) Tabular & Stochastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The second experiment employed the same methodology as the first one. In this case, we turned on the environment slippery, which adds stochasticity. Similarly, we searched for the best solution using the grid search algorithm using the following parameters:\n",
    "\n",
    "$\\mathrm{N0} \\in [1, 100, 1000, 10000]$,\n",
    "\n",
    "$\\mathrm{gamma} \\in [1, 0.9, 0.1]$,\n",
    "\n",
    "$\\mathrm{episodes} \\in [10000, 100000]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "This time we increased the number of episodes and the $N0$ constant to enable more exploration in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         n0  gamma  episodes  win/loss (%)  elapsed time (s)\n",
      "0       1.0    1.0   10000.0           7.0          5.432594\n",
      "1     100.0    1.0   10000.0          28.0          7.623629\n",
      "2    1000.0    1.0   10000.0          55.0          9.491570\n",
      "3   10000.0    1.0   10000.0          36.0         12.016099\n",
      "4       1.0    0.9   10000.0           1.0          5.742304\n",
      "5     100.0    0.9   10000.0          12.0          8.934242\n",
      "6    1000.0    0.9   10000.0          43.0          9.263228\n",
      "7   10000.0    0.9   10000.0           2.0         10.051708\n",
      "8       1.0    0.1   10000.0           4.0          7.212385\n",
      "9     100.0    0.1   10000.0           0.0          8.766804\n",
      "10   1000.0    0.1   10000.0           1.0         11.912093\n",
      "11  10000.0    0.1   10000.0           2.0          9.833791\n",
      "12      1.0    1.0  100000.0          13.0         63.864103\n",
      "13    100.0    1.0  100000.0          26.0         96.923429\n",
      "14   1000.0    1.0  100000.0          60.0        128.208909\n",
      "15  10000.0    1.0  100000.0          53.0        151.927949\n",
      "16      1.0    0.9  100000.0           5.0         44.051018\n",
      "17    100.0    0.9  100000.0          14.0         64.966595\n",
      "18   1000.0    0.9  100000.0          53.0        116.065208\n",
      "19  10000.0    0.9  100000.0          37.0         94.986223\n",
      "20      1.0    0.1  100000.0           3.0         77.387585\n",
      "21    100.0    0.1  100000.0           3.0         99.011985\n",
      "22   1000.0    0.1  100000.0           3.0         75.076992\n",
      "23  10000.0    0.1  100000.0           6.0         83.765707\n"
     ]
    }
   ],
   "source": [
    "grid_search_tabular(stochastic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when the environment is stochastic, the agent has enormous difficulties in learning a good policy. Half of the executions returned a success rate inferior to 10\\%. Nevertheless, the other executions were promising, especially the numbers 14 and 2, with win rates of 60\\% and 55\\%, respectively. The elapsed time has dramatically increased, primarily due to the increase in the number of episodes. The best solution was achieved by providing intermediate exploration with $N0=1000$. Also, the discount factor significantly impacted the win rate; the best results were achieved using a rate greater than 0.9.\n",
    "\n",
    "Now, we will analyze the solution number 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhbklEQVR4nO3de5QcZZ3/8fcn9xtJyJVAEpNAEIMg4KigrrKCGEDhqKhE/HlZlePu4mX56Qqri8ruWa+rwm9RySre1gXxhhGCoICgyCUJIBAgMAmEJAKZEJKQhJDb9/dH1YROZ6aneqare7rr8zpnznQ99VTVt6pm+luXp55SRGBmZsU1oNEBmJlZYzkRmJkVnBOBmVnBORGYmRWcE4GZWcENanQA1ZowYULMmDGj0WGYmTWVJUuWrIuIiV2Na7pEMGPGDBYvXtzoMMzMmoqkld2N86UhM7OCcyIwMys4JwIzs4JzIjAzKzgnAjOzgsstEUi6TNJaSfd3M16SLpbULuleScfkFYuZmXUvzzOCHwBzK4w/GZid/pwNfDvHWMzMrBu5PUcQEbdImlGhyunAjyLpB/t2SWMlTYmIJ/KKKU/Pbd/Ftfc/wVuPPghJPdaPCH5x1xrefOQUhg0euNe47Tt3c9U9a3jHy6ciieuXPslR08YyafQwPnb53XzshNkcMmkUAKuf2cojazfzty+eBMAzW7Zz24qnOeWIKb1elz8+0sH0cSN40fiRe8oef3orK9dv4W9md/k8SpduePAp5hw4miljhnPv6g0IccTUMXvG//b+Jxg0YABTxg5j+87dDBk0gMMPHMP8W5YzefQwTj/qoD1171u9kSA4curYPWU7d+3ml3et4YyXT2XAABER/HzJak476kCGDkq26UNPbuLni1cz71XT+cOyDmaMH8FhU0bz8JPP8reHTWLz8zs596f38OW3H8n+I4cAsPSvG9m+czdPbXqeh596lo+dMJuHn3qWDVt3sPbZbUwfN4KNz+3Ysy227djFz5asZuSQgew/cgizJ41i6v4jALjizsdpX7uZ4188iT8sW8tR08eyZOUzbN62k9/c+1c+edKLmTR6GNfc+1euW/oUnz31JXzob2YBsGTlekYMGcS3/7CcCaOG8paXTeFd82/nq2ccyZwpo3njN27h748/mMMPHM1rD5nAlYtX8R8LH+INh03irxue43WHTuSZLdv52ZLVvLNtKrMmjmLy6KHctXIDLz5gP6aMGcaOXbu5+eEOfnX3Gk45Ygq3tq/jYyfM5vYV6zn8wNGsWr+VSfsN452vmMrPF69mxbotvPXog7jxobX84M+PAXDSnMm8cc5k7nh0PeNHDeHSm1fw+kMncvPDHVx05lF87fplrFr/HACfnnsYt7avY79hg3hq0zbGDB/MTcs6+PTcw/j675YxfdwIlnds2edv6cSXTGL0sMHcvWoD23fuZs2G5xg7YjAbtu4A4LAD9uPNR05h6KCB/ODPj/GuV0zj1/esYXnHFmaMH8G0cSP44yPrAJg8eihPbXo+09/wjPEjOHDscEYMGcjvH1ybaZpOk0cP5ZBJo7i1/em9yo+ZPpa7Ht/AO9umcuXi1d1O/5W3H8lXr19Gx7MvxLrs3+fu+duuJeX5PoI0EVwdES/tYtzVwJci4k/p8A3ApyNin6fFJJ1NctbA9OnTX75yZbfPRTTM+b+8j8vvfJzLP3wsxx08vsf6Nz20lg/8YBF/95qZXPCWOXuN+8bvHuaiGx7hojOP4tQjpnDIZ65l1oSR/L93H82pF/8JgMe+dCoAh1/wW7Zs37Vn+J3fuY07H1vPnf9yApNGD+vVusw475q9ltFdWZb5TNpvKHd+5sR9pt/43A5e9oXr95nm+n96HSd945ZMy59/y3L+Y+FDfPFtRzDvldP57f1P8pH/WcJHXn8w55182F7Tler8AnnsS6dy5vzbuH3FekYMGcgDF87tcprfn/t6Tvz6zfvMpzOWC3/zAJfd+uie8krzyqJzvtVMe8ikUbSv3Vz1sqy5nHDYJL73/lf0alpJSyKiratxTXGzOCLmR0RbRLRNnJj9iLSe1m7aBsCW53dmqr9pW3Ik07F53yOTdWnZpm076UzTj6/fynPbd+1Td0tZ2ZoNyZHX9l27M8WRt7XPdn3ktbOb+Lpax+48vWU7wJ6jws5tuq6LbVqqsz4kZzoAWyssd9uOyjGV78NK88rLo+v2PYq21rPqma25zLeRiWANMK1keGpaZmZmddTIRLAAeG/aeuhYYGOz3h8wM2tmud0slnQ5cDwwQdJq4HPAYICI+A6wEDgFaAe2Ah/IKxYzM+tenq2G5vUwPoB/zGv5ZmaWTVPcLDYzs/w4EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE0GTyK9HqOYXZVsnx+6zzFqSE0GNVfsdVLHTvwh67se020n7te56aM3QcesLdcu2Tm+2VZaeYs1anRNBjVT7fVLpC6i7Uf7O6p+8W6zZORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTQY1U26VDpa4luhoVEf2+24j+orzvoT7Pr4fZebdYs3MiqLFquxuo2NeN1Ou+cPp7dxR5hFfkfoOKu+ZWC04ENVbrTud6HYcPU80sIyeCGnGnc8Xl3WLNzomgn6t4xtDE8lirVt1WWRR3za0WnAiaRJGvf1er/D0FfZ6fN721OCcCM7OCcyIwMys4JwIzs4JzIjAzKzgnAjOzgnMiMDMrOCcCM7OCyzURSJoraZmkdknndTF+uqSbJN0t6V5Jp+QZTzMr8sNSPSnfNPXudM6s2eWWCCQNBC4BTgbmAPMkzSmr9lngyog4GjgT+FZe8Vj/0t0zWtU8DFb+oFdvHrrzw2Jm+Z4RvBJoj4gVEbEduAI4vaxOAKPTz2OAv+YYT11Ue+ReqbYPRM2sHvJMBAcBq0qGV6dlpT4PvEfSamAh8NGuZiTpbEmLJS3u6OjII9YaqO7QslLt7o+Ke16Gj3CrU4vt5W1uza7RN4vnAT+IiKnAKcCPJe0TU0TMj4i2iGibOHFi3YM0M2tleSaCNcC0kuGpaVmpDwJXAkTEbcAwYEKOMZmZWZk8E8EiYLakmZKGkNwMXlBW53HgBABJLyFJBP312o+ZWUvKLRFExE7gHOA64EGS1kFLJV0o6bS02v8FPizpL8DlwPvD7STNzOpqUJ4zj4iFJDeBS8suKPn8APCaPGMwM7PKGn2z2MzMGsyJwMys4Lq9NCTpWSo80xQRo7sbZ2ZmzaPbRBAR+wFI+jfgCeDHJE80nQVMqUt0TaWWTxTvOzYyLsO32qlqV2TZXj31XeRtbs0uy6Wh0yLiWxHxbERsiohvs29XEZaqtr+byk8Y762VvnDyeBq3yA/4Fnndre+yJIItks6SNFDSAElnAVvyDszMzOojSyJ4N/BO4Kn05x1pmXXBnc6ZWbOp+BxB2pX0ORHhS0E9yr/TuSyXU9wBWnXc6ZxZD2cEEbELeG2dYjEzswbI8mTx3ZIWAD+j5N5ARPwyt6jMzKxusiSCYcDTwBtKygJwIqiDVr1PkEcLqFbdVlkUed2t73pMBBHxgXoEYpX5MnQVaryxqnl9plkz6jERSBpG8t6Aw0nODgCIiL/LMS4zM6uTLM1HfwwcALwJuJnkBTPP5hmUmZnVT5ZEcEhE/CuwJSJ+CJwKvCrfsMzMrF6yJIId6e8Nkl4KjAEm5ReSdcU3A6tQ443VU19D/YHf52R9kaXV0HxJ+wP/SvKqyVHpZzMzawFZWg19N/14MzAr33CsKLp7Greap3TLq/ambU+rtAiS1Fq9ElpdZWk1tBy4Hfgj8MeIWJp7VGZmVjdZ7hHMAS4FxgNflbRc0q/yDat5VX1MVmGCvhzg+eDQzLLKkgh2kdww3gXsBtamP2Zm1gKy3CzeBNwHfB3474h4Ot+QmlO1PVBWqt/9uJ4X4p4wq1OT3kf7PguzhspyRjAPuAX4B+AKSV+QdEK+YZmZWb1kaTX0a+DXkg4DTgY+AfwzMDzf0MzMrB56PCOQ9AtJ7cBFwAjgvcD+eQdmZmb1keUewReBu9OX1JiZWYvJco/gAeB8SfMBJM2W9OZ8wzIzs3rJkgi+D2wHXp0OrwH+PbeIzMysrrIkgoMj4iuknc9FxFbcYm4f1T7AVal+V+OSsp4X4gfJqnuoL8v26qmON7k1uyyJYLuk4aR/75IOBp7PNaomVnWGrOJ5gmq+5Pv78wR59PHT39c5TwVedauBLIngc8BvgWmSfgLcQNJ8tEeS5kpaJqld0nnd1HmnpAckLZX0v5kjNzOzmsjyHMHvJN0FHEty4PFxkmakFUkaCFwCvBFYDSyStCAiHiipMxs4H3hNRDwjye85MDOrs4pnBJKOk3QGMDAirgEeBy4Gbs0w71cC7RGxIiK2A1cAp5fV+TBwSUQ8AxAR7sPIzKzOuk0Ekr4KXAa8HbhG0r8D1wN3ALMzzPsgYFXJ8Oq0rNShwKGSbpV0u6S53cRytqTFkhZ3dHRkWHTjuPdRM2s2lS4NnQocHRHb0jeUrQJeGhGP1Xj5s4HjganALZKOiIgNpZUiYj4wH6Ctra1ffsXVo9O5LMso8g3T3nCnc2aVLw1ti4htAOmlm0eqTAJrgGklw1PTslKrgQURsSMiHgUeJtvZhpmZ1UilM4JZkhaUDM8sHY6I03qY9yJgtqSZJAngTODdZXWuIund9PuSJpBcKlqRMXYzM6uBSomg/Mbuf1Yz44jYKekc4DpgIHBZRCyVdCGwOCIWpONOkvQAyYtvPuX3HZiZ1Ve3iSAibu7rzCNiIbCwrOyCks8BnJv+WBda9aZv5PA8bqtuqywKvOpWA1keKLN+wDeBs6v1pvK2t1bnRNAkini0GxlXurxerTdVEbe9FUvmRCCpx6eJzbKqRV9D5UfqvTly98G+WbY3lL06vZn7UDr8Mknfyj0yMzOriyxnBN8A3gQ8DRARfwFel2dQZmZWP5kuDUXEqrIiv7bSzKxFZHln8SpJrwZC0mCS3kcfzDcsMzOrlyxnBB8B/pGkw7g1wFHpsHWh6jeVVWjjkrXVTLXzNTMrleWMQBFxVu6RNLlqW59UajXTmzFZ5mv7Ug0eEqjFPMwaKcsZwa2Srpf0QUlj8w7IzMzqq8dEEBGHAp8FDgfuknS1pPfkHpmZmdVF1lZDd0bEuSRvHVsP/DDXqMzMrG6yPFA2WtL7JF0L/Bl4giQhmJlZC8hys/gvJO8NuDAibss3nOZVbRudiq2F+rCUVmotFFG524jORlXljauqaW2VpW5PNfrSuqtW+kMM1ryyJIJZ4b+yfsF7wbojyX8g1mvdJgJJ34yITwALJO3zF5bhDWWFVPW7iys1Fu1Ds8R+34y0Fu8KVte/i6jAq241UOmM4Mfp76/VIxAzM2uMSm8oW5J+PCoiLiodJ+njQJ/fYGZmZo2Xpfno+7ooe3+N4zAzswapdI9gHvBuYKakBSWj9iN5lsDMzFpApXsEnc8MTAD+s6T8WeDePINqZu50zsyaTaV7BCuBlcBx9QunedWj07ksrWL6fWuhfsadzplle7L4WEmLJG2WtF3SLkmb6hGcmZnlL8vN4v8C5gGPAMOBDwGX5BmUmZnVT9ZO59qBgRGxKyK+D8zNNywzM6uXLF1MbJU0BLhH0ldIbiBnSiBmZtb/ZflC/z/AQOAcYAswDXh7nkGZQfaO/PbpdK7WcbgPH2txPZ4RpK2HAJ4DvpBvOFauaM1Aq2mAU4sWUq3S3qdYfyVWa5UeKLuPCn9fEXFkLhGZmVldVTojeHPdojCroVof5fs5AWt1PT1QZmZmLS7LA2XPStqU/myr5oEySXMlLZPULum8CvXeLikktVUTvJmZ9V2Wm8X7dX5Wco58OnBsT9NJGkjy4NkbgdXAIkkLIuKBsnr7AR8H7qgudDMzq4WqngeIxFXAmzJUfyXQHhErImI7cAVJEin3b8CXgW3VxNJ/Vdd+o1LLxL60BHGLRzPLqsczAklvKxkcALSR7Uv7IGBVyfBq4FVl8z4GmBYR10j6VIUYzgbOBpg+fXqGRddf1a+orFC/+5uTPS/E9zWrVItXZvZ9FmYNleXJ4reUfN4JPEbXR/ZVkTQA+DoZXnITEfOB+QBtbW0+1jUzq6Es9wg+0Mt5ryF5CrnT1LSs037AS4E/pEfABwALJJ0WEYt7uUwzM6tSlktDM4GPAjNK60fEaT1MugiYnU6/BjiT5I1nndNvJHnpTedy/gB80knAzKy+slwaugr4HvAbYHfWGUfETknnANeR9FV0WUQslXQhsDgiFlSeQ3Op+s1klW4Sdzuy54X0l5vEteifJ5lH9Vfgq1pyhso9rUs/2eRmvZYlEWyLiIt7M/OIWAgsLCu7oJu6x/dmGf1PdV9cFW8alw1X893a328a5xFfkd/OVtw1t1rIkggukvQ54Hrg+c7CiLgrt6jMzKxusiSCI0i6on4DL1wainTYzMyaXJZE8A5gVvpQmJmZtZgsTxbfD4zNOQ4zM2uQLGcEY4GHJC1i73sEPTUfNTOzJpAlEXwu9yjMzKxhsjxZfDOApNFZ6ps7nWsWfhexWSLLk8VnAxeSdDS3m6TJcgCz8g3NzMzqIcsR/qeAl0bEuryDaWb16H00yzL6+4Nk/Y57HzXL1GpoObA170DMzKwxspwRnA/8WdId7N1q6GO5RWVG9nsk5fVqfem/Ge4kNEOM1n9lSQSXAjcC91FFp3NmZtYcsiSCwRFxbu6RmFFdx3Hl90N6c3+kVa7vt8p6WGNkuUdwraSzJU2RNK7zJ/fIzMysLrKcEcxLf59fUubmo2ZmLSLLA2Uz6xGIda1Vn3nKY71adVtlUeBVtxrI8kDZe7sqj4gf1T4cMzOrtyyXhl5R8nkYcAJwF+BEYP1SrR+q841Ya3VZLg19tHRY0ljgirwCMjOz+srSaqjcFsD3DbpR25fY9yGO3k9aGEW+p2BWKss9gt/wwvfKAGAOcGWeQZmZWf1kuUfwtZLPO4GVEbE6p3iaVjUPQiX1e7eUfOZbXN118FfdTPo+C7NG6jYRSDoEmNz5PoKS8tdIGhoRy3OProlEte8h6OVS8plv7fX2skvpduxpHp3jy+tVs+ws7yTosUY/2Oh+t4L1RaV7BN8ENnVRvikdZ3Xm/3XrTk3ObKywKiWCyRFxX3lhWjYjt4iaXG3fS9CHOHo/aUP1pq+h8t9FVOBVtxqolAjGVhg3vMZxmJlZg1RKBIslfbi8UNKHgCX5hWRmZvVUqdXQJ4BfSTqLF77424AhwFtzjsvMzOqk20QQEU8Br5b0t8BL0+JrIuLGukRmZmZ1kaWLiZuAm+oQi5mZNUBvupjITNJcScsktUs6r4vx50p6QNK9km6Q9KI84zEzs33llggkDQQuAU4m6ZZinqQ5ZdXuBtoi4kjg58BX8orHzMy6lucZwSuB9ohYERHbSXosPb20QkTcFBFb08Hbgak5xlMX7nSueXgbmSXyTAQHAatKhlenZd35IHBtVyPSdyYvlrS4o6OjhiGamVmu9wiykvQekqapX+1qfETMj4i2iGibOHFifYPLqB6dzmV5ctZPmFbHnc6ZZet9tLfWANNKhqemZXuRdCLwGeD1EfF8jvFYk8nakd8+nc7VOg5fQ7IWl+cZwSJgtqSZkoYAZwILSitIOhq4FDgtItbmGIs1iWoO0GtxIO6DebMcE0FE7ATOAa4DHgSujIilki6UdFpa7avAKOBnku6RtKCb2ZmZWU7yvDRERCwEFpaVXVDy+cQ8l29mZj3rFzeLzcyscZwIzMwKzonAzKzgnAjMzArOicDMrOCcCKwx/JBWTXlzWl84EdRYtf+QlZ6erWZeUfb4a/lwkWR9SCzrNqpFLxTVKPK+s8ZwIjAzKzgnAstFb49pSw+Gezowjj2/o8vyWmmGA3SfRVhfOBE0Ef+vW3dq0ouqFZYTQY1V++9YqfvqvvxrN+sXQ286nau2C/BW5C1gfeFEYGZWcE4EZmYF50RgZlZwTgRmZgXnRGBmVnBOBGZmBedEYGZWcE4EZmYF50RgZlZwTgQ11rjeR8uHi9MfxT59DWVc9+xbqL7bsje7rjh72/LgRFAj1fboUKl+d+OyLKNZu5ZolFpsLndxYc3OicD6laq+mMsq9yYJtsqXeGushTWKE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFVyuiUDSXEnLJLVLOq+L8UMl/TQdf4ekGXnGY2Zm+8otEUgaCFwCnAzMAeZJmlNW7YPAMxFxCPAN4Mt5xWNmZl1TXp2TSToO+HxEvCkdPh8gIr5YUue6tM5tkgYBTwITo0JQbW1tsXjx4qrjuXLRKv77jyuqni6rR9ZuBmCA4OCJo3qs/+i6Lezcnazm7El71++cF8DBE0eyvGMLAKOHDWLTtp17TdNZ95BJo1DJ8IFjhjFy6KA+rUtpXF2VVRJAe8k05dPvimBFul6lJo8eylObngeSdR+QdhtRKabyZZTWKy0rd8ikUXtirDTNmOGD2fjcjn2mr7SMLMuvFFfpvjQr9diXTu3VdJKWRERbV+N6902RzUHAqpLh1cCruqsTETslbQTGA+tKK0k6GzgbYPr06b0KZuyIwcyenO1LrDcmjBrKbSue5o1zJjNwQM89vxw8cRS/Xfokx84ax7iRQ/YaN2XscG55uIMTXzKJIYMGsLxjC7MnjeKQSaO49v4nGTV00J512bU7WLFuC4emwyOGDOQvqzdy1PSxvV6XR9ZuZsqYYXttr207d7Fq/XNVbcP2tZuZNXEksyePYuXTW9kVsdf0nYlg2OAB7NgVDBogjpm+P9fe/yQALz5gvz11H1+/lR27du81/bRxI7jxobW84bBJDBs8gFkTR3Ld0qd49cHjGTtiMAAdm59nw9YdjB0xmA1bky/zzuR66ORRjBs5hDsfXc/hB47mReNHAPDExm1sfn7nnuW8+uDxLHpsPes2bweSLo4i2BPL5NHD+FP7C3+y08eN2DOuN1/mh5ZMO3LIQLZs37VPneGDB/LcjhfKj54+lrsf31D1srKaPm4Ej6/fmtv8LZuL5x2dy3zzTAQ1ExHzgfmQnBH0Zh4nHX4AJx1+QE3jMjNrBXneLF4DTCsZnpqWdVknvTQ0Bng6x5jMzKxMnolgETBb0kxJQ4AzgQVldRYA70s/nwHcWOn+gJmZ1V5ul4bSa/7nANcBA4HLImKppAuBxRGxAPge8GNJ7cB6kmRhZmZ1lOs9gohYCCwsK7ug5PM24B15xmBmZpX5yWIzs4JzIjAzKzgnAjOzgnMiMDMruNy6mMiLpA5gZS8nn0DZU8sF4HUuBq9zMfRlnV8UERO7GtF0iaAvJC3urq+NVuV1LgavczHktc6+NGRmVnBOBGZmBVe0RDC/0QE0gNe5GLzOxZDLOhfqHoGZme2raGcEZmZWxonAzKzgCpMIJM2VtExSu6TzGh1Pb0maJukmSQ9IWirp42n5OEm/k/RI+nv/tFySLk7X+15Jx5TM631p/Uckva+7ZfYXkgZKulvS1enwTEl3pOv207S7cyQNTYfb0/EzSuZxflq+TNKbGrQqmUgaK+nnkh6S9KCk41p9P0v6p/Tv+n5Jl0sa1mr7WdJlktZKur+krGb7VdLLJd2XTnOxpJ5fmRgRLf9D0g32cmAWMAT4CzCn0XH1cl2mAMekn/cDHgbmAF8BzkvLzwO+nH4+BbgWEHAscEdaPg5Ykf7eP/28f6PXr4d1Pxf4X+DqdPhK4Mz083eAv08//wPwnfTzmcBP089z0n0/FJiZ/k0MbPR6VVjfHwIfSj8PAca28n4meXXto8Dwkv37/lbbz8DrgGOA+0vKarZfgTvTukqnPbnHmBq9Ueq04Y8DrisZPh84v9Fx1Wjdfg28EVgGTEnLpgDL0s+XAvNK6i9Lx88DLi0p36tef/shecPdDcAbgKvTP/J1wKDyfUzyDozj0s+D0noq3++l9frbD8nb+h4lbdBRvv9acT/zwjvMx6X77WrgTa24n4EZZYmgJvs1HfdQSfle9br7Kcqloc4/sE6r07Kmlp4KHw3cAUyOiCfSUU8Ck9PP3a17s22TbwL/DOxOh8cDGyKi8y3zpfHvWbd0/Ma0fjOt80ygA/h+ejnsu5JG0sL7OSLWAF8DHgeeINlvS2jt/dypVvv1oPRzeXlFRUkELUfSKOAXwCciYlPpuEgOBVqmXbCkNwNrI2JJo2Opo0Eklw++HRFHA1tILhns0YL7eX/gdJIkeCAwEpjb0KAaoBH7tSiJYA0wrWR4alrWlCQNJkkCP4mIX6bFT0mako6fAqxNy7tb92baJq8BTpP0GHAFyeWhi4Cxkjrfslca/551S8ePAZ6mudZ5NbA6Iu5Ih39OkhhaeT+fCDwaER0RsQP4Jcm+b+X93KlW+3VN+rm8vKKiJIJFwOy09cEQkhtLCxocU6+kLQC+BzwYEV8vGbUA6Gw58D6Sewed5e9NWx8cC2xMT0GvA06StH96JHZSWtbvRMT5ETE1ImaQ7LsbI+Is4CbgjLRa+Tp3bosz0vqRlp+ZtjaZCcwmubHW70TEk8AqSS9Oi04AHqCF9zPJJaFjJY1I/84717ll93OJmuzXdNwmScem2/C9JfPqXqNvmtTx5swpJC1slgOfaXQ8fViP15KcNt4L3JP+nEJybfQG4BHg98C4tL6AS9L1vg9oK5nX3wHt6c8HGr1uGdf/eF5oNTSL5B+8HfgZMDQtH5YOt6fjZ5VM/5l0WywjQ2uKBq/rUcDidF9fRdI6pKX3M/AF4CHgfuDHJC1/Wmo/A5eT3APZQXLm98Fa7legLd1+y4H/oqzBQVc/7mLCzKzginJpyMzMuuFEYGZWcE4EZmYF50RgZlZwTgRmZgXnRGCFJ2mXpHtKfir2TivpI5LeW4PlPiZpQl/nY9ZXbj5qhSdpc0SMasByHyNpF76u3ss2K+UzArNupEfsX0n7dr9T0iFp+eclfTL9/DEl74a4V9IVadk4SVelZbdLOjItHy/peiX97X+X5GGhzmW9J13GPZIulTSwAatsBeVEYAbDyy4Nvatk3MaIOILkCc1vdjHtecDREXEk8JG07AvA3WnZvwA/Sss/B/wpIg4HfgVMB5D0EuBdwGsi4ihgF3BWLVfQrJJBPVcxa3nPpV/AXbm85Pc3uhh/L/ATSVeRdAMBSTcgbweIiBvTM4HRJC8keVtafo2kZ9L6JwAvBxalL5MazgudjpnlzonArLLo5nOnU0m+4N8CfEbSEb1YhoAfRsT5vZjWrM98acissneV/L6tdISkAcC0iLgJ+DRJN8ijgD+SXtqRdDywLpJ3RtwCvDstP5mkEzlIOhs7Q9KkdNw4SS/Kb5XM9uYzArP0HkHJ8G8jorMJ6f6S7gWeJ3ntX6mBwP9IGkNyVH9xRGyQ9HngsnS6rbzQvfAXgMslLQX+TNLtMhHxgKTPAtenyWUH8I/Ayhqvp1mX3HzUrBtu3mlF4UtDZmYF5zMCM7OC8xmBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZwf1/iieT8xlHgGkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q, env = train_tabular(stochastic=True, episodes=10000, gamma=1, n0=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative discounted reward has a large variance due to the stochasticity. However, the agent can reach the goal state most of the time; as the training proceeds, the agent retrieves more rewards. Due to the unknown dynamics, the agent falls into the ice holes more frequently, even when selecting the appropriate action, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFF\u001b[41mH\u001b[0mFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following our methodology, we plot the state value ($V_*$) and the derived policy $\\pi_*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t State Value\n",
      "------------------------------------------------\n",
      " 0.05| 0.06| 0.06| 0.08| 0.08| 0.10| 0.14| 0.12|\n",
      "------------------------------------------------\n",
      " 0.05| 0.07| 0.06| 0.07| 0.08| 0.10| 0.11| 0.13|\n",
      "------------------------------------------------\n",
      " 0.02| 0.01| 0.02| 0.00| 0.05| 0.06| 0.14| 0.14|\n",
      "------------------------------------------------\n",
      " 0.01| 0.01| 0.00| 0.00| 0.01| 0.00| 0.14| 0.17|\n",
      "------------------------------------------------\n",
      " 0.00| 0.00| 0.00| 0.00| 0.01| 0.07| 0.15| 0.23|\n",
      "------------------------------------------------\n",
      " 0.01| 0.00| 0.00| 0.00| 0.00| 0.05| 0.00| 0.35|\n",
      "------------------------------------------------\n",
      " 0.00| 0.00| 0.00| 0.00| 0.00| 0.04| 0.00| 0.59|\n",
      "------------------------------------------------\n",
      " 0.00| 0.00| 0.00| 0.00| 0.25| 0.25| 0.50| 0.00|\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_state_values_tabular(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t Policy/Actions\n",
      "------------------------------------------------\n",
      "  n  |  r  |  s  |  r  |  n  |  r  |  r  |  r  |\n",
      "------------------------------------------------\n",
      "  n  |  n  |  n  |  n  |  r  |  n  |  s  |  l  |\n",
      "------------------------------------------------\n",
      "  r  |  r  |  n  |  l  |  n  |  r  |  r  |  s  |\n",
      "------------------------------------------------\n",
      "  n  |  n  |  l  |  r  |  r  |  n  |  r  |  s  |\n",
      "------------------------------------------------\n",
      "  l  |  l  |  l  |  l  |  n  |  s  |  n  |  r  |\n",
      "------------------------------------------------\n",
      "  l  |  n  |  r  |  s  |  s  |  r  |  s  |  r  |\n",
      "------------------------------------------------\n",
      "  s  |  s  |  r  |  n  |  n  |  s  |  n  |  r  |\n",
      "------------------------------------------------\n",
      "  r  |  l  |  r  |  s  |  s  |  n  |  s  |  s  |\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_policy_tabular(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state value was properly determined; it increases as the agent approaches the goal state. However, a curious behavior has emerged; the agent attempts to stay close to the game's border most of the time. Also, the actions are chosen to exploit the stochastic dynamics of the environment, like going right instead of south. The policy makes the agent avoid the holes in the first place while expecting to reach the desired state through the game's stochasticity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Linear Approximation & Deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w = w + \\alpha_{t}[(G_{t} - x(S)^Tw)x(S)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4)  Linear Approximation & Stochastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5) Monte Carlo Final Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) SARSA(λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bc2cd41e953c5fef78842c12ba7691ebdc7ffc6a5d254d7d57cfc6771d550ba"
  },
  "kernelspec": {
   "display_name": "mo436",
   "language": "python",
   "name": "mo436"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
